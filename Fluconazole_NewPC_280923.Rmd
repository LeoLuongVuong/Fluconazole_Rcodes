---
title: "Fluconazole_NewPC_280923"
author: "Leo"
date: "`r Sys.Date()`"
output: pdf_document
---

### Doing MI - Clustering with ID - 2l.pan method - fixing negative values to 0 280923
### After that, Doing MI - Clustering with ID - 2l.pmm method - 011023

### For the whole 70 imputations - 2l.pan method - fixing negative to lowest possible value from CREAT - 041023

#### Reading the source dataset

```{r reading new FlucTotIV_clean dataset, warning=FALSE}

setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes")
FlucTotIV_clean <- read.csv("FlucTotIV_clean.csv", na.strings = "NA")

```

#### Converting variables into appropriate types

```{r convert data types}

FlucTotIV_clean$SEX <- as.factor(FlucTotIV_clean$SEX)
FlucTotIV_clean$HOSPITAL <- as.factor(FlucTotIV_clean$HOSPITAL)
FlucTotIV_clean$CRRT <- as.factor(FlucTotIV_clean$CRRT)
FlucTotIV_clean$OCC <- as.factor(FlucTotIV_clean$OCC)
FlucTotIV_clean$EVID <- as.factor(FlucTotIV_clean$EVID)

```

#### Converting all the NAs in TAD, AMT, RATE to 0, and First row of DV to 0

```{r convert NAs to 0}

FlucTotIV_clean$TAD[is.na(FlucTotIV_clean$TAD)] <- 0
FlucTotIV_clean$AMT[is.na(FlucTotIV_clean$AMT)] <- 0
FlucTotIV_clean$RATE[is.na(FlucTotIV_clean$RATE)] <- 0

```

```{r convert DV to 0 where TIME equals 0}

FlucTotIV_clean$DV[FlucTotIV_clean$TIME == 0] <- 0

```

#### Creating crrt and non-crrt datasets

```{r crrt & non-crrt dataset, warning=FALSE}

library(dplyr)
crrt_patients <- unique(FlucTotIV_clean[FlucTotIV_clean$CRRT == 1, "ID"])
FlucTotIV_clean_crrt<-FlucTotIV_clean%>%filter(ID%in%crrt_patients)
FlucTotIV_clean_nocrrt<-FlucTotIV_clean%>%filter(!ID%in%(crrt_patients))

# Converting BW2 into BW

FlucTotIV_clean_crrt$BW<-FlucTotIV_clean_crrt$BW2
FlucTotIV_clean_nocrrt$BW<-FlucTotIV_clean_nocrrt$BW2

```

#### Best imputation model for crrt and non-crrt datasets

```{r best imputation crrt dataset}

### I add ID to the model in accordance with the thesis I cited below 280823
impute_CREAT_DOS_INT_crrt <- FlucTotIV_clean_crrt[, c("ID","TIME","RATE","AMT","DV","AGE","SEX","BW","LENGTH", "CRRT","OCC","HOSPITAL","CREAT_DOS_INT")]

# Selecting BW instead of BW2 - 011023

```

```{r best imputation nocrrt dataset}

### I add ID to the model in accordance with the thesis I cited below 280823
impute_CREAT_DOS_INT_nocrrt <- FlucTotIV_clean_nocrrt[, c("ID","TIME","RATE","AMT","DV","AGE","SEX","BW","LENGTH","OCC","HOSPITAL","CREAT_DOS_INT")]

# Selecting BW instead of BW2 - 011023

```

#### Then imputing crrt and non-crrt models using mice.impute.2l.pan function, clustering inside ID

```{r for impute_CREAT_DOS_INT_crrt dataset 2l.pan method, warning=FALSE}

# First 10 imputation

library(mice)
library(pan)
set.seed(123)
imp0 <- mice(impute_CREAT_DOS_INT_crrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT","ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_crrt <- mice::mice(data=impute_CREAT_DOS_INT_crrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_crrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_crrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(124)
imp0 <- mice(impute_CREAT_DOS_INT_crrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT","ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_crrt <- mice::mice(data=impute_CREAT_DOS_INT_crrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_crrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_crrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(125)
imp0 <- mice(impute_CREAT_DOS_INT_crrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT","ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_crrt <- mice::mice(data=impute_CREAT_DOS_INT_crrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_crrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_crrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(126)
imp0 <- mice(impute_CREAT_DOS_INT_crrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT","ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_crrt <- mice::mice(data=impute_CREAT_DOS_INT_crrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_crrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_crrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(127)
imp0 <- mice(impute_CREAT_DOS_INT_crrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT","ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_crrt <- mice::mice(data=impute_CREAT_DOS_INT_crrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_crrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_crrt, action = i))$CREAT_DOS_INT
}

# Can check with density and scatter plot

```

```{r for imputed_CREAT_DOS_INT_nocrrt dataset 2l.pan method, warning=FALSE}

# First 10 imputation

library(mice)
library(pan)
set.seed(123)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(124)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(125)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(126)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(127)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(128)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

# Next 10 imputation

library(mice)
library(pan)
set.seed(129)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pan"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

```

#### Then imputing crrt and non-crrt models using mice.impute.2l.pmm function, clustering inside ID

```{r for impute_CREAT_DOS_INT_crrt dataset 2l.pmm method,warning=FALSE}

library(miceadds)
set.seed(123)
imp0 <- mice(impute_CREAT_DOS_INT_crrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT","ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pmm"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_crrt <- mice::mice(data=impute_CREAT_DOS_INT_crrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_crrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_crrt, action = i))$CREAT_DOS_INT
}

```

```{r for imputed_CREAT_DOS_INT_nocrrt dataset 2l.pmm method, warning=FALSE}

library(miceadds)
set.seed(123)
imp0 <- mice(impute_CREAT_DOS_INT_nocrrt, maxit=0)
predmat <- imp0$predictorMatrix
predmat["CREAT_DOS_INT", "ID"] <- -2
meth <- imp0$method
meth["CREAT_DOS_INT"] <- "2l.pmm"
maxit <- 20
nimp <- 10
imputed_CREAT_DOS_INT_nocrrt <- mice::mice(data=impute_CREAT_DOS_INT_nocrrt,method=meth,predictorMatrix = predmat,maxit=maxit, m=nimp, printFlag = FALSE)
for (i in 1:10) {
        FlucTotIV_clean_nocrrt[[paste0("CREAT", sprintf("%02d", i))]] <- (complete(imputed_CREAT_DOS_INT_nocrrt, action = i))$CREAT_DOS_INT
}

```

#### Adding BW and LENGTH to crrt and non-crrt datasets

```{r using a shorter code to chieve this}

# Define a function to add variables to a dataset
add_variables <- function(dataset, imputed_data, var_name) {
  for (i in 1:10) {
    new_var_name <- paste0(var_name, sprintf("%02d", i))
    dataset[[new_var_name]] <- complete(imputed_data, action = i)[[var_name]]
  }
  return(dataset)
}

# Apply the function to FlucTotIV_clean_crrt and FlucTotIV_clean_nocrrt
FlucTotIV_clean_crrt <- add_variables(FlucTotIV_clean_crrt, imputed_CREAT_DOS_INT_crrt, "BW")
FlucTotIV_clean_crrt <- add_variables(FlucTotIV_clean_crrt, imputed_CREAT_DOS_INT_crrt, "LENGTH")

FlucTotIV_clean_nocrrt <- add_variables(FlucTotIV_clean_nocrrt, imputed_CREAT_DOS_INT_nocrrt, "BW")
FlucTotIV_clean_nocrrt <- add_variables(FlucTotIV_clean_nocrrt, imputed_CREAT_DOS_INT_nocrrt, "LENGTH")

```

#### Then combine 2 datasets into 1 FlucTotIV_clean_imputed dataset

```{r combine into FlucTotIV_clean_imputed}

FlucTotIV_clean_imputed <- rbind(FlucTotIV_clean_crrt, FlucTotIV_clean_nocrrt)
FlucTotIV_clean_imputed <- FlucTotIV_clean_imputed[order(FlucTotIV_clean_imputed$ID, FlucTotIV_clean_imputed$HOSPITAL, FlucTotIV_clean_imputed$TIME), ]

```

#### Now average BW and LENGTH per each ID 

```{r Integrating mean values to the original dataset, warning = FALSE}
# Creating subset of hospital 3 and 4 patients
subset <- FlucTotIV_clean_imputed %>% filter(HOSPITAL %in% c(3,4))

# Creating new variables for mean values
bw_mean_cols <- paste0("BW", sprintf("%02d", 1:10), "_mean")
length_mean_cols <- paste0("LENGTH", sprintf("%02d", 1:10), "_mean")
subset[, bw_mean_cols] <- NA
subset[, length_mean_cols] <- NA

# Filling mean values per ID
for (i in unique(subset$ID)) {
  for (j in 1:10) {
    bw_col <- paste0("BW", sprintf("%02d", 1:10))
    length_col <- paste0("LENGTH", sprintf("%02d", 1:10))
    bw_mean_col <- paste0("BW", sprintf("%02d", 1:10), "_mean")
    length_mean_col <- paste0("LENGTH", sprintf("%02d", 1:10), "_mean")
    subset[subset$ID == i, bw_mean_col[j]] <- mean(subset[subset$ID == i, ][[bw_col[j]]], na.rm = TRUE)
    subset[subset$ID == i, length_mean_col[j]] <- mean(subset[subset$ID == i, ][[length_col[j]]], na.rm = TRUE)
  }
}

# Integrating mean values to the original dataset
FlucTotIV_clean_imputed[, bw_mean_cols] <- NA
FlucTotIV_clean_imputed[, length_mean_cols] <- NA
FlucTotIV_clean_imputed[FlucTotIV_clean_imputed$ID %in% subset$ID, bw_mean_cols] <- subset[, bw_mean_cols]
FlucTotIV_clean_imputed[FlucTotIV_clean_imputed$ID %in% subset$ID, length_mean_cols] <- subset[, length_mean_cols]

```

```{r Replace values of 20 columns with mean values in hospital 3 and 4}
# Replace values of 20 columns with mean values in hospital 3 and 4
for (j in 1:10) {
  bw_col <- paste0("BW", sprintf("%02d", j))
  length_col <- paste0("LENGTH", sprintf("%02d", j))
  bw_mean_col <- paste0("BW", sprintf("%02d", j), "_mean")
  length_mean_col <- paste0("LENGTH", sprintf("%02d", j), "_mean")
  FlucTotIV_clean_imputed[FlucTotIV_clean_imputed$HOSPITAL %in% c(3, 4), bw_col] <- FlucTotIV_clean_imputed[FlucTotIV_clean_imputed$HOSPITAL %in% c(3, 4), bw_mean_col]
  FlucTotIV_clean_imputed[FlucTotIV_clean_imputed$HOSPITAL %in% c(3, 4), length_col] <- FlucTotIV_clean_imputed[FlucTotIV_clean_imputed$HOSPITAL %in% c(3, 4), length_mean_col]
}

# Delete the 20 mean columns
bw_mean_cols <- paste0("BW", sprintf("%02d", 1:10), "_mean")
length_mean_cols <- paste0("LENGTH", sprintf("%02d", 1:10), "_mean")
FlucTotIV_clean_imputed <- FlucTotIV_clean_imputed %>% select(-one_of(bw_mean_cols), -one_of(length_mean_cols))

```

#### Averaging CREAT per ID and OCC, where CREAT_DOS_INT is missing

```{r average accross ID and OCC where CREAT_DOS_INT is missing, warning=FALSE}
library(dplyr)

# Create a subset of rows with missing CREAT_DOS_INT
subset <- FlucTotIV_clean_imputed %>% filter(is.na(CREAT_DOS_INT))

# Calculate the mean values per ID and OCC
mean_cols <- paste0("CREAT", sprintf("%02d", 1:10))
subset <- subset %>%
  group_by(ID, OCC) %>%
  mutate(across(mean_cols, mean, na.rm = TRUE)) %>%
  ungroup()

# Replace the mean across ID and OCC in the actual dataset

FlucTotIV_clean_imputed[is.na(FlucTotIV_clean_imputed$CREAT_DOS_INT), mean_cols] <- subset[, mean_cols]

```

#### Fixing all the negative imputed values to 0 or minimum possible values

```{r fixing negative values to 0}

library(dplyr)

# Probably before this, I need to calculate the % of negative values first
negative_percentage_CREAT <- sapply(FlucTotIV_clean_imputed[, c("CREAT01", "CREAT02", "CREAT03", "CREAT04", "CREAT05", "CREAT06", "CREAT07", "CREAT08", "CREAT09", "CREAT10")], function(col) {
  sum(col < 0, na.rm = TRUE) / length(col) * 100
})
# ranging from 1.8 to 4%

View(negative_percentage_CREAT)
str(negative_percentage_CREAT)

# Replace negative values with respective min positive values of CREAT01 to CREAT10 columns - 02/10/23
FlucTotIV_clean_imputed <- FlucTotIV_clean_imputed %>%
  mutate_at(vars(CREAT01:CREAT10), ~ ifelse(. < 0, min(.[. > 0]), .))

# I'll try with the minimum observed value instead - 02/10/23
FlucTotIV_clean_imputed <- FlucTotIV_clean_imputed %>%
  mutate_at(vars(CREAT01:CREAT10), ~ ifelse(. < 0, min(CREAT,na.rm=TRUE), .))

```

#### Making violin plot when fixing to 0 (2l.pan method)

```{r make violin plots of observed and imputed CREAT values, warning=FALSE}

library(tidyr)

# Assuming your dataset is named FlucTotIV_clean_imputed

# Select the 11 columns by specifying their names explicitly
CREAT_columns <- FlucTotIV_clean_imputed %>%
  select(CREAT_DOS_INT, CREAT01, CREAT02, CREAT03, CREAT04, CREAT05, CREAT06, CREAT07, CREAT08, CREAT09, CREAT10)

# Convert from wide to long
CREAT_long_data <- CREAT_columns %>%
  pivot_longer(cols = everything(), 
               names_to = "Imputation", 
               values_to = "Value")

# Rename the levels of the "Imputation" column
CREAT_long_data$Imputation <- factor(CREAT_long_data$Imputation, 
                                levels = c("CREAT_DOS_INT", "CREAT01", "CREAT02", "CREAT03", "CREAT04", "CREAT05", "CREAT06", "CREAT07", "CREAT08", "CREAT09", "CREAT10"))

library(ggplot2)

# Define a custom color palette
custom_palette <- c("skyblue", "lightgreen", "pink", "orange", "purple",
                    "lightblue", "salmon", "gold", "lightpink", "lightgray", "lightcyan")

# Create a violin plot with custom aesthetics
violin_plot<- ggplot(data = CREAT_long_data, aes(x = Imputation, y = Value, fill = Imputation)) +
  geom_violin(trim = FALSE) +
  labs(title = "Violin Plot of Observed and 10 Imputed CREAT",
       x = NULL,
       y = "Serum Creatinine (mg/dl)") +
  scale_x_discrete(labels = c("Observed", "Imputation 01", "Imputation 02", 
                              "Imputation 03", "Imputation 04", "Imputation 05", 
                              "Imputation 06", "Imputation 07", "Imputation 08", 
                              "Imputation 09", "Imputation 10")) +
  scale_fill_manual(values = custom_palette) +
  theme_bw() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5, color = "black", size = 16, face = "bold"),
        axis.text.x = element_text(color = "black", size = 12),
        axis.text.y = element_text(color = "black", size = 12),
        axis.title.y = element_text(color = "black", size = 14, face = "bold"))

# Exporting the plot

setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/with_dos_int/diagnostic_plots/Violin plots")
ggsave("obs_vs_imp_violin.png", plot = violin_plot, dpi = 300, width = 13, height = 7)

```

#### Calculating the CKDEPI of the imputed values

```{r calculating CKDEPI01 to CKDEPI10 using a short code}

library(dplyr)

# Assuming FlucTotIV_clean_imputed is your dataset
Fluc_NONMEM_mul_impute <- FlucTotIV_clean_imputed

# Define a function to calculate CKDEPI for each CKDEPI column
calculate_CKDEPI <- function(data, creatinine_column, sex_column, age_column, multiplier) {
  CKDEPI <- ifelse(data[[sex_column]] == 1 & data[[creatinine_column]] < 0.9,
                   multiplier * ((data[[creatinine_column]]/0.9)^-0.302) * (0.9938^data[[age_column]]),
                   ifelse(data[[sex_column]] == 1 & data[[creatinine_column]] >= 0.9,
                          multiplier * ((data[[creatinine_column]]/0.9)^-1.200) * (0.9938^data[[age_column]]),
                          ifelse(data[[sex_column]] == 2 & data[[creatinine_column]] < 0.7,
                                 multiplier * ((data[[creatinine_column]]/0.7)^-0.241) * (0.9938^data[[age_column]]) * 1.012,
                                 multiplier * ((data[[creatinine_column]]/0.7)^-1.200) * (0.9938^data[[age_column]]) * 1.012)
                   )
  )
  return(CKDEPI)
}

# Calculate CKDEPI01 to CKDEPI10
for (i in 1:10) {
  CKDEPI_column <- paste0("CKDEPI", sprintf("%02d", i))
  Fluc_NONMEM_mul_impute[[CKDEPI_column]] <- calculate_CKDEPI(Fluc_NONMEM_mul_impute, 
                                                               paste0("CREAT", sprintf("%02d", i)), 
                                                               "SEX", "AGE", 142)
}

# View the resulting dataset
View(Fluc_NONMEM_mul_impute)

```

#### Making individual plots to compare between interval variability

```{r making invidivual plots comparing BIV}

# creating a new CREAT_imputed column

Fluc_NONMEM_mul_impute$Creat_imputed<-ifelse(Fluc_NONMEM_mul_impute$unique_CREAT==0,1,0)

# subset data that has both imputed and non-imputed CREAT

library(dplyr)

Imputed_ID <- Fluc_NONMEM_mul_impute %>%
  group_by(ID) %>%
  filter(all(c(0, 1) %in% Creat_imputed)) %>%
  ungroup()

# Count the number of distinct ID
Imputed_ID %>%
  distinct(ID) %>%
  n_distinct()

# Eliminate all the duplicates ID, OCC, unique_CREAT and Creat_imputed from Imputed_data dataset
library(dplyr)

unique_Imputed_ID <- Imputed_ID %>%
  distinct(ID, OCC, unique_CREAT, Creat_imputed, .keep_all = TRUE)

# Need to recalculate CKDEPI still. I use calculate_CKDEPI function from above

unique_Imputed_ID[["CKDEPI"]] <- calculate_CKDEPI(unique_Imputed_ID, 
                                                              "CREAT", 
                                                               "SEX", "AGE", 142)

# Relocate CKDEPI column right next to CKDEPI01
library(dplyr)
unique_Imputed_ID <- unique_Imputed_ID %>%
  relocate(CKDEPI, .before = CKDEPI01)

# Select patients with at least two OCC of unique_CREAT of at least 1
library(dplyr)

OCC_two_CREAT_ID <- unique_Imputed_ID %>%
  group_by(ID) %>%
  filter(n_distinct(OCC) >= 2 & sum(unique_CREAT >= 1, na.rm = TRUE) >= 2) %>%
  select(ID) %>%
  distinct()

OCC_two_CREAT <- unique_Imputed_ID %>%
  filter(ID %in% OCC_two_CREAT_ID$ID)

# Converting from short to longer format

library(tidyr)

Imputed_Creat_Long <- OCC_two_CREAT %>%
  pivot_longer(cols = c(CKDEPI01, CKDEPI02, CKDEPI03, CKDEPI04, CKDEPI05, CKDEPI06, CKDEPI07, CKDEPI08, CKDEPI09, CKDEPI10),                names_to = "Imputed_CKDEPI", 
               values_to = "Value") %>%
  select(ID,OCC,TIME, Imputed_CKDEPI, Creat_imputed, Value)

# And making scatter plots

library(ggplot2)
library(gridExtra)

Imputed_Creat_Long <- Imputed_Creat_Long %>%
  mutate(Creat_imputed = factor(Creat_imputed, levels = c(0, 1), labels = c("No", "Yes")),  # Convert Creat_imputed to factor with labels
         ID = as.integer(ID))  # Create a numerical ID for grouping

# Define the title and label options
title_options <- list(
  label = "CKDEPI over Time of the first 10 imputations",
  size = 14,
  color = "black",
  hjust = 0.5,
  vjust = 1,
  face = "bold"
)

x_label_options <- list(
  label = "Time (h)",
  size = 12,
  color = "black",
  hjust = 0.5,
  vjust = 0
)

y_label_options <- list(
  label = "CKDEPI (ml/min/1.73m2)",
  size = 12,
  color = "black",
  hjust = 0,
  vjust = 0.5,
  angle = 0
)

axis_text_options <- list(
  size = 10
)

legend_options <- list(
  title = "CREAT Imputed",
  size = 8
)

# Create a function to generate scatter plots with custom styling
create_scatter_plots <- function(data, ids) {
  max_value <- max(data[data$ID %in% ids, ]$Value)  # Maximum Value for setting y-axis limit
  ggplot(data = data[data$ID %in% ids, ], aes(x = TIME, y = Value, color = Creat_imputed)) +
    geom_point (size = 3, alpha = 1) +
    facet_wrap(~ID, ncol = 2) +
    labs(title = title_options,
         x = x_label_options,
         y = y_label_options) +
    scale_color_manual(values = c("No" = "dodgerblue4", "Yes" = "goldenrod1"), 
                       name = legend_options) +
   scale_y_continuous(limits = c(0, max_value*1.1), breaks = seq(0, max_value*1.1, by = 10)) +
   # Set y-axis limit
    theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5),
      axis.text = element_text(axis_text_options),
      legend.position = "bottom"
    )
}

# Split the patient IDs into groups of 2 for paneling
id_groups <- split(unique(Imputed_Creat_Long$ID), ceiling(seq_along(unique(Imputed_Creat_Long$ID))/2))
# Create the scatter plots in panels
panel_plots <- lapply(id_groups, function(ids) {
  create_scatter_plots(Imputed_Creat_Long, ids)
})

# Export the plots as high-resolution images
output_dir <- "C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Plots/2l.pan method"
#output_dir <- "C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Plots/2l.pmm method"
if (!dir.exists(output_dir)) dir.create(output_dir)

for (i in seq_along(panel_plots)) {
  ggsave(filename = paste0(output_dir, "/scatter_plot_panel_", i, ".png"),
         plot = panel_plots[[i]],
         width = 10,
         height = 7,
         dpi = 300)
}

```

#### Converting all NAs to -99

```{r NAs to -99}

Fluc_NONMEM_mul_impute[is.na(Fluc_NONMEM_mul_impute)] <- -99

```

#### Convert back to NONMEM format

```{r DV from 0 & -99 to "."}

Fluc_NONMEM_mul_impute$DV <- ifelse(Fluc_NONMEM_mul_impute$DV %in% c(0, -99), ".", Fluc_NONMEM_mul_impute$DV)

```

```{r AMT TAD and RATE from 0 to "."}

Fluc_NONMEM_mul_impute$TAD <- ifelse(Fluc_NONMEM_mul_impute$TAD == 0, ".", Fluc_NONMEM_mul_impute$TAD)
Fluc_NONMEM_mul_impute$AMT <- ifelse(Fluc_NONMEM_mul_impute$AMT == 0, ".", Fluc_NONMEM_mul_impute$AMT)
Fluc_NONMEM_mul_impute$RATE <- ifelse(Fluc_NONMEM_mul_impute$RATE == 0, ".", Fluc_NONMEM_mul_impute$RATE)

```

#### Exporting BW dataset

```{r select appropriate datasets}

FlucTotIV_clean_imputed <- Fluc_NONMEM_mul_impute[, !names(Fluc_NONMEM_mul_impute) %in%c("CMT", "APACHE", "RACE", "CL24", "GGT", "AFT", "ALT", "AST", "BILI", "ALB", "SOFA", "IHD", "UF", "ECMO", "OCC3", "ARCCKD", "ARC24", "ARCAlg", "BMI", "BSA", "dup","FLUID",paste0("CREAT", sprintf("%02d", 1:10)),paste0("LENGTH", sprintf("%02d", 1:10)),"CREAT_DOS_INT","unique_CREAT","CREAT3","CRRT2","dosing_interval","Creat_imputed")]

```

```{r Fluc_NONMEM_mul_impute_BW01 dataset, warning=FALSE}

# When using 2l.pan method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pan")

# First 10 imputation
#write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW01.csv",quote=F,row.names = FALSE)

# Next 10 imputation
# write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW02.csv",quote=F,row.names = FALSE)

# Next 10 imputation
#write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW03.csv",quote=F,row.names = FALSE)

# Next 10 imputation
# write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW04.csv",quote=F,row.names = FALSE)

# Next 10 imputation
# write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW05.csv",quote=F,row.names = FALSE)

# Next 10 imputation
#write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW06.csv",quote=F,row.names = FALSE)

# Next 10 imputation
write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW07.csv",quote=F,row.names = FALSE)

# When using 2l.pmm method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pmm")
write.csv(FlucTotIV_clean_imputed, "Fluc_NONMEM_mul_impute_BW01.csv",quote=F,row.names = FALSE)

```

#### Adding ARC column, using the CKDEPI cut-off of 96.5 ml/min

```{r creating ARC01 to ARC10 columns corresponding to CKDEPI01 to CKDEPI10}

# Define a vector of column names from CKDEPI01 to CKDEPI10
ckdepi_cols <- paste0("CKDEPI", sprintf("%02d", 1:10))

# Loop through each column and create the corresponding ARC column
for (i in 1:10) {
  col_name <- paste0("ARC", sprintf("%02d", i))
  FlucTotIV_clean_imputed[[col_name]] <- as.integer(FlucTotIV_clean_imputed[[ckdepi_cols[i]]] >= 96.5)
}

# Creating a new dataset

FlucTotIV_clean_imputed_ARC <- FlucTotIV_clean_imputed

# Eliminating CKDEPI01 to CKDEPI10
FlucTotIV_clean_imputed_ARC <- FlucTotIV_clean_imputed_ARC %>%
  select(-CKDEPI01, -CKDEPI02, -CKDEPI03, -CKDEPI04, -CKDEPI05, 
         -CKDEPI06, -CKDEPI07, -CKDEPI08, -CKDEPI09, -CKDEPI10)

```

#### Exporting ARC dataset

```{r Fluc_NONMEM_mul_impute_ARC01 dataset, warning=FALSE}

# When using 2l.pmm method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pmm")
write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC01.csv",quote=F,row.names = FALSE)

# When using 2l.pan method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pan")

# First 10 imputations
#write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC01.csv",quote=F,row.names = FALSE)

# The next 10 imputations
# write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC02.csv",quote=F,row.names = FALSE)

# The next 10 imputations
# write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC03.csv",quote=F,row.names = FALSE)

# The next 10 imputations
# write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC04.csv",quote=F,row.names = FALSE)

# The next 10 imputations
# write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC05.csv",quote=F,row.names = FALSE)

# The next 10 imputations
# write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC06.csv",quote=F,row.names = FALSE)

# The next 10 imputations
write.csv(FlucTotIV_clean_imputed_ARC, "Fluc_NONMEM_mul_impute_ARC07.csv",quote=F,row.names = FALSE)

```

#### Pooling parameters of 70 2l.pan imputed models - 051023

```{r set wd, warning=FALSE}

# Read in the dataset
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Pooled_datasets")
Pooling_Parameters_2l.pan<-read.csv("Pooling_Parameters_2l.pan_051023.csv",sep=";")

# Creating Var (Variance) column 
Pooling_Parameters_2l.pan$Var<-(Pooling_Parameters_2l.pan$RSE*Pooling_Parameters_2l.pan$Estimates/100)^2

```

##### First of all, CKDEPI

```{r calculate Mean Within and Between Subject variability for all}

CKDEPI<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CKDEPI"]) #0.4794

W_CKDEPI<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "CKDEPI"]) #0.0255248 #within imputation variance

B_CKDEPI<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CKDEPI"]) #0.008850446 #between imputation variance

CKDEPI
W_CKDEPI
B_CKDEPI

```

```{r total variance for all}

m<-70
T_CKDEPI<-W_CKDEPI+(1+1/m)*B_CKDEPI #0.03450169
T_CKDEPI

```

```{r confidence interval - T distribution}
m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_CKDEPI<-(B_CKDEPI+B_CKDEPI/m)/T_CKDEPI #proportion of variation attributable to the missing data
r_CKDEPI<-(lambda_CKDEPI)/(1-lambda_CKDEPI) #relative increase in variance due to nonresponse
v_old_CKDEPI<-(m-1)*(1+1/r_CKDEPI^2) #old degree of freedom
v_com=n-k #degree of freedom of parameter estimate (CKDEPI) in the hypothetically complete data
v_obs_CKDEPI=((v_com+1)/(v_com+3))*v_com*(1-lambda_CKDEPI) #observed data degrees of freedom that accounts for the missing information
v_CKDEPI<-(v_old_CKDEPI*v_obs_CKDEPI)/(v_old_CKDEPI+v_obs_CKDEPI) 
t_crit_CKDEPI <- qt(0.975, v_CKDEPI) 

lower_bound_CKDEPI<-CKDEPI-t_crit_CKDEPI*sqrt(T_CKDEPI) #0.1109361
upper_bound_CKDEPI<-CKDEPI+t_crit_CKDEPI*sqrt(T_CKDEPI) #0.8478639

lower_bound_CKDEPI
upper_bound_CKDEPI

```

##### Second of all, CLcrrt

```{r calculate Mean Within and Between Subject variability for all}

CLcrrt<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CLcrrt"]) #1.691857

W_CLcrrt<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "CLcrrt"]) #0.018215 #within imputation variance

B_CLcrrt<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CLcrrt"]) #2.113872e-05 #between imputation variance

CLcrrt
W_CLcrrt
B_CLcrrt

```

```{r total variance for all}

m<-70
T_CLcrrt<-W_CLcrrt+(1+1/m)*B_CLcrrt #0.01823644
T_CLcrrt

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_CLcrrt<-(B_CLcrrt+B_CLcrrt/m)/T_CLcrrt #proportion of variation attributable to the missing data

r_CLcrrt<-(lambda_CLcrrt)/(1-lambda_CLcrrt) #relative increase in variance due to nonresponse

v_old_CLcrrt<-(m-1)*(1+1/r_CLcrrt^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (CLcrrt) in the hypothetically complete data

v_obs_CLcrrt=((v_com+1)/(v_com+3))*v_com*(1-lambda_CLcrrt) #observed data degrees of freedom that accounts for the missing information

v_CLcrrt<-(v_old_CLcrrt*v_obs_CLcrrt)/(v_old_CLcrrt+v_obs_CLcrrt)

t_crit_CLcrrt <- qt(0.975, v_CLcrrt) 

lower_bound_CLcrrt<-CLcrrt-t_crit_CLcrrt*sqrt(T_CLcrrt) #1.425197
upper_bound_CLcrrt<-CLcrrt+t_crit_CLcrrt*sqrt(T_CLcrrt) #1.958517

lower_bound_CLcrrt
upper_bound_CLcrrt

```

##### Third of all, CLr

```{r calculate Mean Within and Between Subject variability for all}

CLr<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CLr"]) #0.6262857

W_CLr<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "CLr"]) #0.0009582094 #within imputation variance

B_CLr<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CLr"]) #4.759834e-05
#between imputation variance

CLr
W_CLr
B_CLr

```

```{r total variance for all}

m<-70
T_CLr<-W_CLr+(1+1/m)*B_CLr #0.001006488
T_CLr

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_CLr<-(B_CLr+B_CLr/m)/T_CLr #proportion of variation attributable to the missing data

r_CLr<-(lambda_CLr)/(1-lambda_CLr) #relative increase in variance due to nonresponse

v_old_CLr<-(m-1)*(1+1/r_CLr^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (CLr) in the hypothetically complete data

v_obs_CLr=((v_com+1)/(v_com+3))*v_com*(1-lambda_CLr) #observed data degrees of freedom that accounts for the missing information

v_CLr<-(v_old_CLr*v_obs_CLr)/(v_old_CLr+v_obs_CLr)

t_crit_CLr <- qt(0.975, v_CLr) 

lower_bound_CLr<-CLr-t_crit_CLr*sqrt(T_CLr) #0.5636141
upper_bound_CLr<-CLr+t_crit_CLr*sqrt(T_CLr) #0.6889574

lower_bound_CLr
upper_bound_CLr

```

##### Next, V1

```{r calculate Mean Within and Between Subject variability for all}

V1<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "V1"]) #38.51857

W_V1<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "V1"]) #11.20266 #within imputation variance

B_V1<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "V1"]) #0.101824
#between imputation variance

V1
W_V1
B_V1

```

```{r total variance for all}

m<-70
T_V1<-W_V1+(1+1/m)*B_V1 #11.30594
T_V1

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_V1<-(B_V1+B_V1/m)/T_V1 #proportion of variation attributable to the missing data

r_V1<-(lambda_V1)/(1-lambda_V1) #relative increase in variance due to nonresponse

v_old_V1<-(m-1)*(1+1/r_V1^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (V1) in the hypothetically complete data

v_obs_V1=((v_com+1)/(v_com+3))*v_com*(1-lambda_V1) #observed data degrees of freedom that accounts for the missing information

v_V1<-(v_old_V1*v_obs_V1)/(v_old_V1+v_obs_V1)

t_crit_V1 <- qt(0.975, v_V1) 

lower_bound_V1<-V1-t_crit_V1*sqrt(T_V1) #31.87858
upper_bound_V1<-V1+t_crit_V1*sqrt(T_V1) #45.15857

lower_bound_V1
upper_bound_V1

```

##### After that, Q

```{r calculate Mean Within and Between Subject variability for all}

Q<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "Q"]) #12.33286

W_Q<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "Q"]) #23.7237 #within imputation variance

B_Q<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "Q"]) #0.05933954
#between imputation variance

Q
W_Q
B_Q

```

```{r total variance for all}

m<-70
T_Q<-W_Q+(1+1/m)*B_Q #23.78388
T_Q

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_Q<-(B_Q+B_Q/m)/T_Q #proportion of variation attributable to the missing data

r_Q<-(lambda_Q)/(1-lambda_Q) #relative increase in variance due to nonresponse

v_old_Q<-(m-1)*(1+1/r_Q^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (Q) in the hypothetically complete data

v_obs_Q=((v_com+1)/(v_com+3))*v_com*(1-lambda_Q) #observed data degrees of freedom that accounts for the missing information

v_Q<-(v_old_Q*v_obs_Q)/(v_old_Q+v_obs_Q)

t_crit_Q <- qt(0.975, v_Q) 

lower_bound_Q<-Q-t_crit_Q*sqrt(T_Q) #2.702697
upper_bound_Q<-Q+t_crit_Q*sqrt(T_Q) #21.96302

lower_bound_Q
upper_bound_Q

```

##### Next, V2

```{r calculate Mean Within and Between Subject variability for all}

V2<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "V2"]) #8.714286

W_V2<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "V2"]) #9.882814 #within imputation variance

B_V2<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "V2"]) #0.005677019
#between imputation variance

V2
W_V2
B_V2

```

```{r total variance for all}

m<-70
T_V2<-W_V2+(1+1/m)*B_V2 #9.888572
T_V2

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_V2<-(B_V2+B_V2/m)/T_V2 #proportion of variation attributable to the missing data

r_V2<-(lambda_V2)/(1-lambda_V2) #relative increase in variance due to nonresponse

v_old_V2<-(m-1)*(1+1/r_V2^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (V2) in the hypothetically complete data

v_obs_V2=((v_com+1)/(v_com+3))*v_com*(1-lambda_V2) #observed data degrees of freedom that accounts for the missing information

v_V2<-(v_old_V2*v_obs_V2)/(v_old_V2+v_obs_V2)

t_crit_V2 <- qt(0.975, v_V2) 

lower_bound_V2<-V2-t_crit_V2*sqrt(T_V2) #2.504844
upper_bound_V2<-V2+t_crit_V2*sqrt(T_V2) #14.92373

lower_bound_V2
upper_bound_V2

```

##### Next, BW

```{r calculate Mean Within and Between Subject variability for all}

BW<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "BW"]) #1.032786

W_BW<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "BW"]) #0.03541545 #within imputation variance

B_BW<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "BW"]) #0.0003502578
#between imputation variance

BW
W_BW
B_BW

```

```{r total variance for all}

m<-70
T_BW<-W_BW+(1+1/m)*B_BW #0.03577071
T_BW

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_BW<-(B_BW+B_BW/m)/T_BW #proportion of variation attributable to the missing data

r_BW<-(lambda_BW)/(1-lambda_BW) #relative increase in variance due to nonresponse

v_old_BW<-(m-1)*(1+1/r_BW^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (BW) in the hypothetically complete data

v_obs_BW=((v_com+1)/(v_com+3))*v_com*(1-lambda_BW) #observed data degrees of freedom that accounts for the missing information

v_BW<-(v_old_BW*v_obs_BW)/(v_old_BW+v_obs_BW)

t_crit_BW <- qt(0.975, v_BW) 

lower_bound_BW<-BW-t_crit_BW*sqrt(T_BW) #0.659294
upper_bound_BW<-BW+t_crit_BW*sqrt(T_BW) #1.406277

lower_bound_BW
upper_bound_BW

```

##### Next, Cov_CLr_V1

```{r for this special case I need preliminary treatment}

# First of all, replacing the Var with the values in RSE column

library(dplyr)

Pooling_Parameters_2l.pan <- Pooling_Parameters_2l.pan %>%
  mutate(Var = ifelse(Parameters == "Cov_CLr_V1", RSE^2, Var))

# Second of all, replacing the values of the RSE column

Pooling_Parameters_2l.pan <- Pooling_Parameters_2l.pan %>%
mutate(RSE = ifelse(Parameters == "Cov_CLr_V1", (RSE/Estimates)*100, RSE))

```

```{r calculate Mean Within and Between Subject variability for all}

Cov_CLr_V1<-mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "Cov_CLr_V1"]) #0.07843

W_Cov_CLr_V1<-mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "Cov_CLr_V1"]) #0.001475356 #within imputation variance

B_Cov_CLr_V1<-var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "Cov_CLr_V1"]) #1.735083e-05
#between imputation variance

Cov_CLr_V1
W_Cov_CLr_V1
B_Cov_CLr_V1

```

```{r total variance for all}

m<-70
T_Cov_CLr_V1<-W_Cov_CLr_V1+(1+1/m)*B_Cov_CLr_V1 #0.001492955
T_Cov_CLr_V1

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_Cov_CLr_V1<-(B_Cov_CLr_V1+B_Cov_CLr_V1/m)/T_Cov_CLr_V1 #proportion of variation attributable to the missing data

r_Cov_CLr_V1<-(lambda_Cov_CLr_V1)/(1-lambda_Cov_CLr_V1) #relative increase in variance due to nonresponse

v_old_Cov_CLr_V1<-(m-1)*(1+1/r_Cov_CLr_V1^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (Cov_CLr_V1) in the hypothetically complete data

v_obs_Cov_CLr_V1=((v_com+1)/(v_com+3))*v_com*(1-lambda_Cov_CLr_V1) #observed data degrees of freedom that accounts for the missing information

v_Cov_CLr_V1<-(v_old_Cov_CLr_V1*v_obs_Cov_CLr_V1)/(v_old_Cov_CLr_V1+v_obs_Cov_CLr_V1)

t_crit_Cov_CLr_V1 <- qt(0.975, v_Cov_CLr_V1) 

lower_bound_Cov_CLr_V1<-Cov_CLr_V1-t_crit_Cov_CLr_V1*sqrt(T_Cov_CLr_V1) #0.002126054
upper_bound_Cov_CLr_V1<-Cov_CLr_V1+t_crit_Cov_CLr_V1*sqrt(T_Cov_CLr_V1) #0.1547339

lower_bound_Cov_CLr_V1
upper_bound_Cov_CLr_V1

```

##### Thereafter, with IIVs and Prop.Err, they are variance terms, so I will log-transform them first, then use Rubin's Rule to pool the parameter estimates, then back-transform to get the actual esmates

```{r create a log-transformed Log column}

Pooling_Parameters_2l.pan$Log<-log(Pooling_Parameters_2l.pan$Estimates)

```

```{r create a Var_Log variable}

# Variance of the log-transformed variable

Pooling_Parameters_2l.pan$Var_Log<-(1/(Pooling_Parameters_2l.pan$Estimates))^2*Pooling_Parameters_2l.pan$Var #Var(log(x))=[1/(mean(x))]^2*var(x) (log(x) in R is actually ln(x))

```

##### First, we deal with IIV_CLcrrt log-transformed estimate - IIV_CLcrrt_log, then back-transform to IIV_CLcrrt

```{r calculate Mean Within and Between Subject variability for all}

IIV_CLcrrt_log<-mean(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "IIV_CLcrrt"]) #1.723017

W_IIV_CLcrrt_log<-mean(Pooling_Parameters_2l.pan$Var_Log[Pooling_Parameters_2l.pan$Parameters == "IIV_CLcrrt"]) #0.1443013 #within imputation variance

B_IIV_CLcrrt_log<-var(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "IIV_CLcrrt"]) #0.0001843056 #between imputation variance

IIV_CLcrrt_log
W_IIV_CLcrrt_log
B_IIV_CLcrrt_log

```

```{r total variance for log-transformed variable}

m<-70
T_IIV_CLcrrt_log<-W_IIV_CLcrrt_log+(1+1/m)*B_IIV_CLcrrt_log #0.1444883
T_IIV_CLcrrt_log

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_IIV_CLcrrt_log<-(B_IIV_CLcrrt_log+B_IIV_CLcrrt_log/m)/T_IIV_CLcrrt_log #proportion of variation attributable to the missing data

r_IIV_CLcrrt_log<-(lambda_IIV_CLcrrt_log)/(1-lambda_IIV_CLcrrt_log) #relative increase in variance due to nonresponse

v_old_IIV_CLcrrt_log<-(m-1)*(1+1/r_IIV_CLcrrt_log^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (IIV_CLcrrt_log) in the hypothetically complete data

v_obs_IIV_CLcrrt_log=((v_com+1)/(v_com+3))*v_com*(1-lambda_IIV_CLcrrt_log) #observed data degrees of freedom that accounts for the missing information

v_IIV_CLcrrt_log<-(v_old_IIV_CLcrrt_log*v_obs_IIV_CLcrrt_log)/(v_old_IIV_CLcrrt_log+v_obs_IIV_CLcrrt_log)

t_crit_IIV_CLcrrt_log <- qt(0.975, v_IIV_CLcrrt_log) 

lower_bound_IIV_CLcrrt_log<-IIV_CLcrrt_log-t_crit_IIV_CLcrrt_log*sqrt(T_IIV_CLcrrt_log) #-2.47361
upper_bound_IIV_CLcrrt_log<-IIV_CLcrrt_log+t_crit_IIV_CLcrrt_log*sqrt(T_IIV_CLcrrt_log) #-0.9724246

lower_bound_IIV_CLcrrt_log
upper_bound_IIV_CLcrrt_log

```

```{r back transform IIV_CLcrrt_log to IIV_CLcrrt}

IIV_CLcrrt<-exp(IIV_CLcrrt_log) #0.1785267

lower_bound_IIV_CLcrrt<-exp(lower_bound_IIV_CLcrrt_log) #0.08428006

upper_bound_IIV_CLcrrt<-exp(upper_bound_IIV_CLcrrt_log) #0.378165

IIV_CLcrrt

lower_bound_IIV_CLcrrt

upper_bound_IIV_CLcrrt

```

##### Second, we deal with IIV_CLr log-transformed estimate - IIV_CLr_log, then back-transform to IIV_CLr

```{r calculate Mean Within and Between Subject variability for all}

IIV_CLr_log<-mean(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "IIV_CLr"]) #-1.511388

W_IIV_CLr_log<-mean(Pooling_Parameters_2l.pan$Var_Log[Pooling_Parameters_2l.pan$Parameters == "IIV_CLr"]) #0.0377679 #within imputation variance

B_IIV_CLr_log<-var(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "IIV_CLr"]) #0.001016345 #between imputation variance

IIV_CLr_log
W_IIV_CLr_log
B_IIV_CLr_log

```

```{r total variance for log-transformed variable}

m<-70
T_IIV_CLr_log<-W_IIV_CLr_log+(1+1/m)*B_IIV_CLr_log #0.001016345
T_IIV_CLr_log

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_IIV_CLr_log<-(B_IIV_CLr_log+B_IIV_CLr_log/m)/T_IIV_CLr_log #proportion of variation attributable to the missing data

r_IIV_CLr_log<-(lambda_IIV_CLr_log)/(1-lambda_IIV_CLr_log) #relative increase in variance due to nonresponse

v_old_IIV_CLr_log<-(m-1)*(1+1/r_IIV_CLr_log^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (IIV_CLr_log) in the hypothetically complete data

v_obs_IIV_CLr_log=((v_com+1)/(v_com+3))*v_com*(1-lambda_IIV_CLr_log) #observed data degrees of freedom that accounts for the missing information

v_IIV_CLr_log<-(v_old_IIV_CLr_log*v_obs_IIV_CLr_log)/(v_old_IIV_CLr_log+v_obs_IIV_CLr_log)

t_crit_IIV_CLr_log <- qt(0.975, v_IIV_CLr_log) 

lower_bound_IIV_CLr_log<-IIV_CLr_log-t_crit_IIV_CLr_log*sqrt(T_IIV_CLr_log) #-1.900422
upper_bound_IIV_CLr_log<-IIV_CLr_log+t_crit_IIV_CLr_log*sqrt(T_IIV_CLr_log) #-1.122355

lower_bound_IIV_CLr_log
upper_bound_IIV_CLr_log

```

```{r back transform IIV_CLr_log to IIV_CLr}

IIV_CLr<-exp(IIV_CLr_log) #0.2206035

lower_bound_IIV_CLr<-exp(lower_bound_IIV_CLr_log) #0.1495055

upper_bound_IIV_CLr<-exp(upper_bound_IIV_CLr_log) #0.3255125

IIV_CLr

lower_bound_IIV_CLr

upper_bound_IIV_CLr

```

##### After that, we deal with IIV_V1 log-transformed estimate - IIV_V1_log, then back-transform to IIV_V1

```{r calculate Mean Within and Between Subject variability for all}

IIV_V1_log<-mean(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "IIV_V1"]) #-1.240382

W_IIV_V1_log<-mean(Pooling_Parameters_2l.pan$Var_Log[Pooling_Parameters_2l.pan$Parameters == "IIV_V1"]) #0.0452367 #within imputation variance

B_IIV_V1_log<-var(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "IIV_V1"]) #0.0001839721 #between imputation variance

IIV_V1_log
W_IIV_V1_log
B_IIV_V1_log

```

```{r total variance for log-transformed variable}

m<-70
T_IIV_V1_log<-W_IIV_V1_log+(1+1/m)*B_IIV_V1_log #0.0454233
T_IIV_V1_log

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_IIV_V1_log<-(B_IIV_V1_log+B_IIV_V1_log/m)/T_IIV_V1_log #proportion of variation attributable to the missing data

r_IIV_V1_log<-(lambda_IIV_V1_log)/(1-lambda_IIV_V1_log) #relative increase in variance due to nonresponse

v_old_IIV_V1_log<-(m-1)*(1+1/r_IIV_V1_log^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (IIV_V1_log) in the hypothetically complete data

v_obs_IIV_V1_log=((v_com+1)/(v_com+3))*v_com*(1-lambda_IIV_V1_log) #observed data degrees of freedom that accounts for the missing information

v_IIV_V1_log<-(v_old_IIV_V1_log*v_obs_IIV_V1_log)/(v_old_IIV_V1_log+v_obs_IIV_V1_log)

t_crit_IIV_V1_log <- qt(0.975, v_IIV_V1_log) 

lower_bound_IIV_V1_log<-IIV_V1_log-t_crit_IIV_V1_log*sqrt(T_IIV_V1_log) #-1.661241
upper_bound_IIV_V1_log<-IIV_V1_log+t_crit_IIV_V1_log*sqrt(T_IIV_V1_log) #-0.8195228

lower_bound_IIV_V1_log
upper_bound_IIV_V1_log

```

```{r back transform IIV_V1_log to IIV_V1}

IIV_V1<-exp(IIV_V1_log) #0.2892737

lower_bound_IIV_V1<-exp(lower_bound_IIV_V1_log) #0.1899032

upper_bound_IIV_V1<-exp(upper_bound_IIV_V1_log) #0.4406419

IIV_V1

lower_bound_IIV_V1

upper_bound_IIV_V1

```

##### Finally, we deal with PropErr log-transformed estimate - PropErr_log, then back-transform to PropErr

```{r calculate Mean Within and Between Subject variability for all}

PropErr_log<-mean(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "PropErr"]) #-3.593393

W_PropErr_log<-mean(Pooling_Parameters_2l.pan$Var_Log[Pooling_Parameters_2l.pan$Parameters == "PropErr"]) #0.01827621 #within imputation variance

B_PropErr_log<-var(Pooling_Parameters_2l.pan$Log[Pooling_Parameters_2l.pan$Parameters == "PropErr"]) #6.42266e-05
 #between imputation variance

PropErr_log
W_PropErr_log
B_PropErr_log

```

```{r total variance for log-transformed variable}

m<-70
T_PropErr_log<-W_PropErr_log+(1+1/m)*B_PropErr_log #0.01834136
T_PropErr_log

```

```{r confidence interval - T distribution}

m<-70 #number of imputations
k<-12 #my model has 12 parameters (including 6 fixed effects parameters and 6 random effect parameters where covariance is one of them)
n<-177

lambda_PropErr_log<-(B_PropErr_log+B_PropErr_log/m)/T_PropErr_log #proportion of variation attributable to the missing data

r_PropErr_log<-(lambda_PropErr_log)/(1-lambda_PropErr_log) #relative increase in variance due to nonresponse

v_old_PropErr_log<-(m-1)*(1+1/r_PropErr_log^2) #old degree of freedom

v_com=n-k #degree of freedom of parameter estimate (PropErr_log) in the hypothetically complete data

v_obs_PropErr_log=((v_com+1)/(v_com+3))*v_com*(1-lambda_PropErr_log) #observed data degrees of freedom that accounts for the missing information

v_PropErr_log<-(v_old_PropErr_log*v_obs_PropErr_log)/(v_old_PropErr_log+v_obs_PropErr_log)

t_crit_PropErr_log <- qt(0.975, v_PropErr_log) 

lower_bound_PropErr_log<-PropErr_log-t_crit_PropErr_log*sqrt(T_PropErr_log) #-3.860824
upper_bound_PropErr_log<-PropErr_log+t_crit_PropErr_log*sqrt(T_PropErr_log) #-3.325962

lower_bound_PropErr_log
upper_bound_PropErr_log

```

```{r back transform PropErr_log to PropErr}

PropErr<-exp(PropErr_log) #0.02750484

lower_bound_PropErr<-exp(lower_bound_PropErr_log) #0.02105065

upper_bound_PropErr<-exp(upper_bound_PropErr_log) #0.03593792

PropErr

lower_bound_PropErr

upper_bound_PropErr

```

#### Evaluate the adequacy of the number of imputations (for later - 091023)

```{r set wd, warning=FALSE}

# Read in the dataset
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Pooled_datasets")
Pooling_Parameters_2l.pan<-read.csv("Pooling_Parameters_2l.pan_051023.csv",sep=";")

# Creating Var (Variance) column 
Pooling_Parameters_2l.pan$Var<-(Pooling_Parameters_2l.pan$RSE*Pooling_Parameters_2l.pan$Estimates/100)^2

```

```{r calculate variance Theta Within and Between Subject variability for 70 imputations, warning=FALSE}

# Create empty vectors
m <- Theta <- W <- B <- Total_Var <- numeric(70)

# Assign values to vectors using for loop
for (i in 1:70) {
  m[i] <- i
  Theta[i] <- mean(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CKDEPI" & Pooling_Parameters_2l.pan$Model <= i])
  W[i] <- mean(Pooling_Parameters_2l.pan$Var[Pooling_Parameters_2l.pan$Parameters == "CKDEPI" & Pooling_Parameters_2l.pan$Model <= i])
  B[i] <- var(Pooling_Parameters_2l.pan$Estimates[Pooling_Parameters_2l.pan$Parameters == "CKDEPI" & Pooling_Parameters_2l.pan$Model <= i])
  Total_Var[i] <- W[i] + (1 + 1 / m[i]) * B[i]
}

# Combine vectors into a data frame
imputation_number <- data.frame(m, Theta, Total_Var)

```

```{r plot Theta over m, warning=FALSE}

library(ggplot2)

x_label_options <- list(
  label = "Number of imputations",
  size = 12,
  color = "black",
  hjust = 0.5,
  vjust = 0,
  face = "bold"
)

y_label_options <- list(
  label = "CKDEPI effect Estimate",
  size = 12,
  color = "black",
  hjust = 0,
  vjust = 0.5,
  angle = 0,
  face = "bold"
)

axis_text_options <- list(
  size = 10
)

Theta_over_m<-ggplot(imputation_number, aes(x = m)) +
  geom_line(aes(y = Theta, color = "Parameter Estimate"), size = 1.0) +
  geom_point(aes(y = Theta, color = "Parameter Estimate"), size = 2.5) + # Add points for Parameter Estimate
  scale_color_manual(values = c("dodgerblue4")) +
  scale_x_continuous(breaks = seq(0, 70, 10), limits = c(0, 70))  +
  scale_y_continuous(breaks = seq(0, 0.55, 0.05), limits = c(0, 0.55)) +
  labs(x = x_label_options,
         y = y_label_options) +
  theme_bw() + 
  theme(axis.text = element_text(axis_text_options),
        legend.position = "none")
Theta_over_m

#labs(x = "Number of imputations", y = "CKDEPI effect Estimate", color = "Variables") +

# Exporting the plot
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/diagnostic_plots/2l.pan")  

ggsave("theta_over_m_091023.png", plot = Theta_over_m, dpi = 300, width = 12, height = 8)

```

```{r plot variance over m, warning=FALSE}

library(ggplot2)

x_label_options <- list(
  label = "Number of imputations",
  size = 12,
  color = "black",
  hjust = 0.5,
  vjust = 0,
  face = "bold"
)

y_label_options <- list(
  label = "Total variance of CKDEPI effect estimate",
  size = 12,
  color = "black",
  hjust = 0,
  vjust = 0.5,
  angle = 0,
  face = "bold"
)

axis_text_options <- list(
  size = 10
)

var_over_m<-ggplot(imputation_number, aes(x = m)) +
  geom_line(aes(y = Total_Var, color = "Total Variance"), size = 1.0) +
  geom_point(aes(y = Total_Var, color = "Total Variance"), size = 2.5) + # Add points for Total Variance
  scale_color_manual(values = c("goldenrod1")) +
  scale_x_continuous(breaks = seq(0, 70, 10), limits = c(0, 70))  +
  scale_y_continuous(breaks = seq(0, 0.042, 0.003), limits = c(0, 0.042)) +
  labs(x = x_label_options,
         y = y_label_options) +
  theme_bw() + 
  theme(axis.text = element_text(axis_text_options),
        legend.position = "none")
var_over_m

# Exporting the plot
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/diagnostic_plots/2l.pan")  

ggsave("var_over_m_091023.png", plot = var_over_m, dpi = 300, width = 12, height = 8)

```

#### Making diagnostic plots of CKDEPI over TIME observed vs imputed; and density plot

```{r reading first imputed dataset 2l.pan method,warning=FALSE}

# For 2l.pan method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pan")
Fluc_NONMEM_mul_impute_BW01 <- read.csv("Fluc_NONMEM_mul_impute_BW01.csv")

# For 2l.pmm method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pmm")
Fluc_NONMEM_mul_impute_BW01 <- read.csv("Fluc_NONMEM_mul_impute_BW01.csv")

# Assigning -99 in CKDEPI and CREAT to NA
Fluc_NONMEM_mul_impute_BW01$CKDEPI[Fluc_NONMEM_mul_impute_BW01$CKDEPI == -99] <- NA
Fluc_NONMEM_mul_impute_BW01$CREAT[Fluc_NONMEM_mul_impute_BW01$CREAT == -99] <- NA

# This will no longer be necessary as I already exported the new dataset FlucTotIV_clean in which I recalculated CKDEPI - 051023
Fluc_NONMEM_mul_impute_BW01[["CKDEPI"]] <- calculate_CKDEPI(Fluc_NONMEM_mul_impute_BW01,"CREAT", 
                                                            "SEX", "AGE", 142)

```

```{r CKDEPI over TIME imputed vs non-imputed}

## Creat_Imputed variable indicating whether CREAT is missing or imputed
## Value of 1 means yes, and 0 means no

Fluc_NONMEM_mul_impute_BW01$Creat_Imputed<-ifelse(is.na(Fluc_NONMEM_mul_impute_BW01$CREAT),1,0)

## Making 10 plots with trend lines

library(ggplot2)

# Create a list to store the plots
plot_list <- list()

# Loop through CKDEPI01 to CKDEPI10
for (i in 1:10) {
  # Create a plot for each CKDEPI variable
  plot <- ggplot(Fluc_NONMEM_mul_impute_BW01, aes(x = TIME, y = get(paste0("CKDEPI", sprintf("%02d", i))), color = factor(Creat_Imputed))) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +  # Add trend line
    labs(title = paste("CKDEPI", sprintf("%02d", i), "over Time"),
         x = "Time (h)", y = paste("eGFR (ml/min/1.73m2)"),
         color = "Creatinine Imputed") + 
    scale_color_discrete(labels = c("No", "Yes")) +
    theme_bw() +
        scale_y_continuous(breaks = seq(0, 300, by = 20), limits = c(0, 300),expand = c(0,0)) +
        scale_x_continuous(breaks = seq(0, 1100, by = 50), limits = c(0, 1100),expand = c(0,0)) +
        theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 12),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  ) 
  
  # Add the plot to the list
  plot_list[[i]] <- plot
}

# Print and export the plots
for (i in 1:10) {
  # Print the plot
  print(plot_list[[i]])
  
# Export the plot to a high-quality image

  # 2l.pan method  
  setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/diagnostic_plots/2l.pan")  
  ggsave(paste("CKDEPI", sprintf("%02d", i), "_plot.png"), plot = plot_list[[i]], dpi = 300, width = 12, height = 8)
  # 2l.pmm method
#setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/diagnostic_plots/2l.pmm")  
  #ggsave(paste("CKDEPI", sprintf("%02d", i), "_plot.png"), plot = plot_list[[i]], dpi = 300, width = 12, height = 8)
}

```

```{r density plot observed vs imputed, warning=FALSE}
library(ggplot2)

# Your dataset and initial plot code
# Assuming your dataset is called Fluc_NONMEM_mul_impute_BW01
# ...

# Define the title and label options
title_options <- list(
  label = "Density plot of 10 imputed CKDEPI vs the original CKDEPI",
  size = 14,
  color = "black",
  hjust = 0.5,
  vjust = 1,
  face = "bold"
)

x_label_options <- list(
  label = "eGFR (ml/min/1.73m2)",
  size = 12,
  color = "black",
  hjust = 0.5,
  vjust = 0
)

y_label_options <- list(
  label = "Density",
  size = 12,
  color = "black",
  hjust = 0,
  vjust = 0.5,
  angle = 0
)

axis_text_options <- list(
  size = 10
)

legend_options <- list(
  title = "Variable",
  size = 8
)

# Density plot first 10 imputations 
density_plot<-ggplot(Fluc_NONMEM_mul_impute_BW01, aes(x = CKDEPI01)) + 
  geom_density(aes(fill = "CKDEPI01"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI02, fill = "CKDEPI02"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI03, fill = "CKDEPI03"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI04, fill = "CKDEPI04"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI05, fill = "CKDEPI05"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI06, fill = "CKDEPI06"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI07, fill = "CKDEPI07"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI08, fill = "CKDEPI08"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI09, fill = "CKDEPI09"), alpha = 0.5) + 
  geom_density(aes(x = CKDEPI10, fill = "CKDEPI10"), alpha = 0.5) +
  geom_density(aes(x = CKDEPI, fill = "CKDEPI"), alpha = 0.5) +
  theme_bw() +
  scale_fill_manual(
    name = "Variable",
    values = c("CKDEPI01" = "blue", "CKDEPI02" = "lightblue", "CKDEPI03" = "green",
               "CKDEPI04" = "orange", "CKDEPI05" = "purple", "CKDEPI06" = "pink",
               "CKDEPI07" = "brown", "CKDEPI08" = "gray", "CKDEPI09" = "black",
               "CKDEPI10" = "yellow","CKDEPI" = "red")
  ) + labs(title = title_options,
         x = x_label_options,
         y = y_label_options) +
  theme(
      plot.title = element_text(hjust = 0.5),
      axis.text = element_text(axis_text_options),
      legend.position = "right"
    )

# 2l.pan method
#setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/diagnostic_plots/2l.pan")  
#ggsave("Density_2l.pan_051023.png", plot = density_plot, dpi = 300, width = 12, height = 8)

# 2l.pmm method
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/diagnostic_plots/2l.pmm")  
ggsave("Density_2l.pmm_051023.png", plot = density_plot, dpi = 300, width = 12, height = 8)

```

### Making VPC - 111023

#### First of all, calculate mean BW and CKDEPI of the total 70 imputations

```{r calculate mean BW and CKDEPI - BW_ave and CKDEPI_ave, warning=FALSE}

# Set wd
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pan")

library(dplyr)
library(readr)

# Create a list to store all datasets
datasets <- list()
# Repeat Steps 1 and 2 for the other datasets
for (i in 1:7) {
  # Generate the dataset name
  dataset_name <- paste0("Fluc_NONMEM_mul_impute_BW0", i, ".csv")
  
  # Read the dataset
  data  <- read.csv(dataset_name)

  # Create "BW_ave0i" in the current dataset
  data  <- data  %>%
    mutate(!!paste0("BW_ave0", i) := rowMeans(select(data , BW01:BW10), na.rm = TRUE))
  
   # Create "CKDEPI_ave0i" in the current dataset
  data  <- data  %>%
    mutate(!!paste0("CKDEPI_ave0", i) := rowMeans(select(data , CKDEPI01:CKDEPI10), na.rm = TRUE))
  
  # Add the dataset to the list
  
  datasets[[i]] <- data 
  
}

# Combine the datasets by columns
combined_dataset <- bind_cols(datasets)

# Calculate the mean of "BW_ave01" to "BW_ave07" columns and create "BW_ave"
combined_dataset <- combined_dataset %>%
  mutate(BW_ave = rowMeans(select(., starts_with("BW_ave0")), na.rm = TRUE))

# Calculate the mean of "CKDEPI_ave01" to "CKDEPI_ave07" columns and create "CKDEPI_ave"
combined_dataset <- combined_dataset %>%
  mutate(CKDEPI_ave = rowMeans(select(., starts_with("CKDEPI_ave0")), na.rm = TRUE))

# Add "BW_ave" to the "Fluc_NONMEM_mul_impute_BW01.csv" dataset
datasets[[1]]$BW_ave<-combined_dataset$BW_ave

# Add "CKDEPI_ave" to the "Fluc_NONMEM_mul_impute_BW01.csv" dataset
datasets[[1]]$CKDEPI_ave<-combined_dataset$CKDEPI_ave

# Excluding "BW_ave01" column
datasets[[1]]$BW_ave01<-NULL
datasets[[1]]$CKDEPI_ave01<-NULL

# Exporting the dataset
setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/My datasets and R codes/Imputed_dos_int_datasets/2l method/2l.pan/vpc")
write.csv(datasets[[1]], "Fluc_NONMEM_mul_impute_BW01.csv",quote=F,row.names = FALSE)

```

#### Then making vpc, code copied from pcVPC_pooled.R



### Doing simulation - 091023
#### First of all, check the correlation between BW & CKDEPI

```{r correlation BW & CKDEPI}

cor(FlucTotIV_clean$CKDEPI,FlucTotIV_clean$BW2) #Equal NA
# Note: in cor(x,y), y needs to have compatible dimensions to x
FlucTotIV_clean %>% filter (!is.na(CKDEPI)) %>% summarize(correlation = cor(CKDEPI, BW2,method="pearson")) #-0.175662 #weak negative #Ask Erwin if it can be ignored?

```

#### Creating simulation datasets, seperately for CRRT and non-CRRT
##### Here I try using previously created datasets

```{r import virtual patient dataset dosing_08, warning=FALSE}

setwd("C:/Users/u0164053/OneDrive - KU Leuven/Fluconazole PoPPK/Fluconazol_project/Bootstrap and dosing simulation/BW_Simulations/Simulation datasets")
sim_dosing_01<-read.csv("dosing_08.csv")

# With dose-finding simulation, we don't need a dense sampling strategy, since we only care about trough and AUC-24 target attainment

```

```{r checking normal distribution of CKDEPI}

# Test if CKDEPI has a normal distribution
library(dplyr)
test <- FlucTotIV_clean %>% select(ID, CKDEPI,CRRT) %>% unique() %>% mutate(CKDEPI2 = log10(CKDEPI))
library(ggplot2)

test<-na.omit(test)

# Making a qqplot
qqnorm(test$CKDEPI, pch = 1, frame = FALSE)
qqline(test$CKDEPI, col = "steelblue", lwd = 2)

shapiro.test(test$CKDEPI) # p-value = 4.691e-11 - non-normal

# For the log-transformed CKDEPI
qqnorm(test$CKDEPI2, pch = 1, frame = FALSE)
qqline(test$CKDEPI2, col = "steelblue", lwd = 2)

shapiro.test(test$CKDEPI2) #p-value = 1.281e-15

# normal distribution doesn't work

```

```{r comparing CKDEPI of CRRT vs non-CRRT}
# comparing if CRRT vs non-CRRT patients have a different distribution

crrt_ids<-unique(test$ID[test$CRRT == 1])

# Perform Mann-Whitney U test
non_parametric_test <- wilcox.test(CKDEPI ~ ifelse(ID %in% crrt_ids, "CRRT", "Non-CRRT"), data = test)

# Print the test results
print(non_parametric_test) #p=1.434e-12 #crrt & non-crrt patients have different CKDEPI distributions

#CRRT and non-CRRT patients does not have a similar CKDEPI distribution

# Summary statistics of CRRT vs non-CRRT patients
library(dplyr)

# Calculate summary statistics for CKDEPI for patients in crrt_ids
summary_in_crrt <- test %>%
  filter(ID %in% crrt_ids) %>%
  summarize(
    Mean_CKDEPI = mean(CKDEPI, na.rm = TRUE),
    Median_CKDEPI = median(CKDEPI, na.rm = TRUE),
    Min_CKDEPI = min(CKDEPI, na.rm = TRUE),
    Max_CKDEPI = max(CKDEPI, na.rm = TRUE),
    SD_CKDEPI = sd(CKDEPI, na.rm = TRUE)
  )

# Calculate summary statistics for CKDEPI for patients not in crrt_ids
summary_not_in_crrt <- test %>%
  filter(!ID %in% crrt_ids) %>%
  summarize(
    Mean_CKDEPI = mean(CKDEPI, na.rm = TRUE),
    Median_CKDEPI = median(CKDEPI, na.rm = TRUE),
    Min_CKDEPI = min(CKDEPI, na.rm = TRUE),
    Max_CKDEPI = max(CKDEPI, na.rm = TRUE),
    SD_CKDEPI = sd(CKDEPI, na.rm = TRUE)
  )
summary_in_crrt
summary_not_in_crrt

```


```{r finetune dosing_08 dataset, warning=FALSE}

# Eliminate all rows with PEAK == 1
library(dplyr)
sim_dosing_01<- sim_dosing_01 %>% filter(PEAK==0)

# Eliminate PEAK column
sim_dosing_01$PEAK<-NULL



```
